{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Mark_number=['“','؟','.','ّ','ُ','ً','َ','ِ','ٍ','~',',',':','،','!','(',')','{','}','/','’','ٌ','”','\\'','\\'','ِ','َ','0']\n",
    "number=np.arange(0,10)\n",
    "number=pd.Series(number)\n",
    "number=number.apply(lambda x:str(x))\n",
    "charactersA=['أ','آ','ى','إ','ء','ئ']\n",
    "charactersT=['ة']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proccessstopword(stopword):\n",
    "    stopword=delete_Marks_numberc(stopword,Mark_number,'')\n",
    "    stopword=delete_Marks_numberc(stopword,Mark_number[3],'')\n",
    "    stopword=delete_Marks_numberc(stopword,charactersA,'ا')\n",
    "    stopword=delete_Marks_numberc(stopword,charactersT,'ه')\n",
    "    stopword=delete_Marks_numberc(stopword,number,' ')\n",
    "    #stopword=add_space_to_separate_word(stopword)#about 0.5 hour\n",
    "    return stopword\n",
    "\n",
    "def proccessReview(review):\n",
    "        \n",
    "        review=proccessstopword(review)\n",
    "        review=delet_word_stop(review,stopwordsproccessed)#about 10 minute\n",
    "        #review=delete_Marks_numberc(review,stopwordsproccessed,' ')about 0.5 hour\n",
    "        return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_Marks_numberc(wordd,Mark_number,character):\n",
    "    for i in range(len(Mark_number)):\n",
    "        wordd=wordd.replace(Mark_number[i],character)\n",
    "    return wordd\n",
    "def delete_stop_word(word,stopwords):\n",
    "    for tword in stopwords:\n",
    "        if(word==tword):\n",
    "            word=''\n",
    "    return word\n",
    "def delet_word_stop(word,stopword):\n",
    "    Axis=word.split(' ')\n",
    "    Axis=pd.Series(Axis)\n",
    "    Axis=Axis.apply(lambda x:delete_stop_word(x,stopword))\n",
    "    Axis=' '.join(Axis)\n",
    "    return Axis\n",
    "def add_space_to_separate_word(word):\n",
    "    return ' '+word+' '\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info=pd.read_csv('DataProccessed.csv')\n",
    "dat=pd.read_csv('dataset.csv')\n",
    "stopwords=pd.read_csv('stopwords.csv')\n",
    "list_stopword=stopwords['stopwords']\n",
    "stopwordsproccessed=list_stopword.apply(lambda x:proccessstopword(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set=info['Review']\n",
    "labled=dat['rating']\n",
    "labled[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toknizer=Tokenizer(num_words=100,oov_token='<oov>')\n",
    "toknizer.fit_on_texts(data_set)\n",
    "toknizer.fit_on_texts(labled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=toknizer.word_index\n",
    "data_set=toknizer.texts_to_sequences(data_set)\n",
    "#labled=toknizer.texts_to_sequences(labled)\n",
    "#labled=pad_sequences(labled,padding='post',truncating='post')\n",
    "data_set=pad_sequences(data_set,padding='post',maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         7\n",
       "1         5\n",
       "2         5\n",
       "3         1\n",
       "4         4\n",
       "         ..\n",
       "104995    5\n",
       "104996    5\n",
       "104997    5\n",
       "104998    4\n",
       "104999    2\n",
       "Name: rating, Length: 105000, dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traning_data=data_set[0:105000]\n",
    "labltraning=labled[0:105000]\n",
    "labltraning\n",
    "labltraning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84000 samples, validate on 21000 samples\n",
      "Epoch 1/500\n",
      "27808/84000 [========>.....................] - ETA: 6s - loss: 1.3544 - acc: 0.3606"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-84114b397397>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraning_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabltraning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensor\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(units=50, input_shape=(traning_data.shape[1],), activation='sigmoid'))\n",
    "model.add(Dense(units=80, activation='sigmoid'))\n",
    "model.add(Dense(units=80, activation='sigmoid'))\n",
    "model.add(Dense(units=40, activation='relu'))\n",
    "model.add(Dense(units=40, activation='sigmoid'))\n",
    "model.add(Dense(units=25, activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',metrics=['acc'])\n",
    "model.fit(traning_data, labltraning, epochs=500, batch_size=32,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(traning_data, labltraning,test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemodel=svm.SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "treemodel.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(hidden_layer_sizes=(20,50),activation='logistic',solver='sgd',learning_rate_init=0.01,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.33178743\n",
      "Iteration 2, loss = 1.32548145\n",
      "Iteration 3, loss = 1.31976877\n",
      "Iteration 4, loss = 1.31390829\n",
      "Iteration 5, loss = 1.30642803\n",
      "Iteration 6, loss = 1.29848380\n",
      "Iteration 7, loss = 1.28890915\n",
      "Iteration 8, loss = 1.27853793\n",
      "Iteration 9, loss = 1.26849265\n",
      "Iteration 10, loss = 1.26002915\n",
      "Iteration 11, loss = 1.25440666\n",
      "Iteration 12, loss = 1.24935482\n",
      "Iteration 13, loss = 1.24505344\n",
      "Iteration 14, loss = 1.24175496\n",
      "Iteration 15, loss = 1.23889658\n",
      "Iteration 16, loss = 1.23599167\n",
      "Iteration 17, loss = 1.23292088\n",
      "Iteration 18, loss = 1.23014025\n",
      "Iteration 19, loss = 1.22789756\n",
      "Iteration 20, loss = 1.22633828\n",
      "Iteration 21, loss = 1.22465671\n",
      "Iteration 22, loss = 1.22255051\n",
      "Iteration 23, loss = 1.22115453\n",
      "Iteration 24, loss = 1.21878171\n",
      "Iteration 25, loss = 1.21745714\n",
      "Iteration 26, loss = 1.21758591\n",
      "Iteration 27, loss = 1.21571677\n",
      "Iteration 28, loss = 1.21440632\n",
      "Iteration 29, loss = 1.21245858\n",
      "Iteration 30, loss = 1.21151183\n",
      "Iteration 31, loss = 1.21008653\n",
      "Iteration 32, loss = 1.20864084\n",
      "Iteration 33, loss = 1.20718115\n",
      "Iteration 34, loss = 1.20606890\n",
      "Iteration 35, loss = 1.20430343\n",
      "Iteration 36, loss = 1.20280131\n",
      "Iteration 37, loss = 1.20179456\n",
      "Iteration 38, loss = 1.19979491\n",
      "Iteration 39, loss = 1.19791085\n",
      "Iteration 40, loss = 1.19577020\n",
      "Iteration 41, loss = 1.19331634\n",
      "Iteration 42, loss = 1.19136467\n",
      "Iteration 43, loss = 1.18909164\n",
      "Iteration 44, loss = 1.18680635\n",
      "Iteration 45, loss = 1.18396217\n",
      "Iteration 46, loss = 1.18148423\n",
      "Iteration 47, loss = 1.17867593\n",
      "Iteration 48, loss = 1.17433487\n",
      "Iteration 49, loss = 1.16947392\n",
      "Iteration 50, loss = 1.16338319\n",
      "Iteration 51, loss = 1.15754311\n",
      "Iteration 52, loss = 1.15350731\n",
      "Iteration 53, loss = 1.14972140\n",
      "Iteration 54, loss = 1.14600173\n",
      "Iteration 55, loss = 1.14224935\n",
      "Iteration 56, loss = 1.13781931\n",
      "Iteration 57, loss = 1.13464687\n",
      "Iteration 58, loss = 1.13113963\n",
      "Iteration 59, loss = 1.12862925\n",
      "Iteration 60, loss = 1.12613320\n",
      "Iteration 61, loss = 1.12416356\n",
      "Iteration 62, loss = 1.12200267\n",
      "Iteration 63, loss = 1.12021230\n",
      "Iteration 64, loss = 1.11825718\n",
      "Iteration 65, loss = 1.11691765\n",
      "Iteration 66, loss = 1.11595401\n",
      "Iteration 67, loss = 1.11444800\n",
      "Iteration 68, loss = 1.11402079\n",
      "Iteration 69, loss = 1.11202458\n",
      "Iteration 70, loss = 1.11120232\n",
      "Iteration 71, loss = 1.11052422\n",
      "Iteration 72, loss = 1.10851431\n",
      "Iteration 73, loss = 1.10796965\n",
      "Iteration 74, loss = 1.10830936\n",
      "Iteration 75, loss = 1.10621010\n",
      "Iteration 76, loss = 1.10553881\n",
      "Iteration 77, loss = 1.10455408\n",
      "Iteration 78, loss = 1.10384845\n",
      "Iteration 79, loss = 1.10353537\n",
      "Iteration 80, loss = 1.10194005\n",
      "Iteration 81, loss = 1.09988330\n",
      "Iteration 82, loss = 1.09941772\n",
      "Iteration 83, loss = 1.09870056\n",
      "Iteration 84, loss = 1.09714203\n",
      "Iteration 85, loss = 1.09738836\n",
      "Iteration 86, loss = 1.09669569\n",
      "Iteration 87, loss = 1.09511727\n",
      "Iteration 88, loss = 1.09520284\n",
      "Iteration 89, loss = 1.09341708\n",
      "Iteration 90, loss = 1.09312342\n",
      "Iteration 91, loss = 1.09228444\n",
      "Iteration 92, loss = 1.09147781\n",
      "Iteration 93, loss = 1.09115760\n",
      "Iteration 94, loss = 1.09092634\n",
      "Iteration 95, loss = 1.08900021\n",
      "Iteration 96, loss = 1.08898561\n",
      "Iteration 97, loss = 1.08789161\n",
      "Iteration 98, loss = 1.08748187\n",
      "Iteration 99, loss = 1.08751090\n",
      "Iteration 100, loss = 1.08719807\n",
      "Iteration 101, loss = 1.08653284\n",
      "Iteration 102, loss = 1.08585095\n",
      "Iteration 103, loss = 1.08540338\n",
      "Iteration 104, loss = 1.08526289\n",
      "Iteration 105, loss = 1.08566195\n",
      "Iteration 106, loss = 1.08390004\n",
      "Iteration 107, loss = 1.08339302\n",
      "Iteration 108, loss = 1.08324409\n",
      "Iteration 109, loss = 1.08268219\n",
      "Iteration 110, loss = 1.08210862\n",
      "Iteration 111, loss = 1.08224968\n",
      "Iteration 112, loss = 1.08139041\n",
      "Iteration 113, loss = 1.07977284\n",
      "Iteration 114, loss = 1.08037617\n",
      "Iteration 115, loss = 1.08040507\n",
      "Iteration 116, loss = 1.07984460\n",
      "Iteration 117, loss = 1.07899157\n",
      "Iteration 118, loss = 1.07912400\n",
      "Iteration 119, loss = 1.07833647\n",
      "Iteration 120, loss = 1.07833432\n",
      "Iteration 121, loss = 1.07757713\n",
      "Iteration 122, loss = 1.07725889\n",
      "Iteration 123, loss = 1.07715146\n",
      "Iteration 124, loss = 1.07648474\n",
      "Iteration 125, loss = 1.07667351\n",
      "Iteration 126, loss = 1.07617154\n",
      "Iteration 127, loss = 1.07531850\n",
      "Iteration 128, loss = 1.07530246\n",
      "Iteration 129, loss = 1.07488914\n",
      "Iteration 130, loss = 1.07407664\n",
      "Iteration 131, loss = 1.07414500\n",
      "Iteration 132, loss = 1.07311977\n",
      "Iteration 133, loss = 1.07306774\n",
      "Iteration 134, loss = 1.07296022\n",
      "Iteration 135, loss = 1.07252021\n",
      "Iteration 136, loss = 1.07283236\n",
      "Iteration 137, loss = 1.07259416\n",
      "Iteration 138, loss = 1.07230752\n",
      "Iteration 139, loss = 1.07220655\n",
      "Iteration 140, loss = 1.07067378\n",
      "Iteration 141, loss = 1.07087181\n",
      "Iteration 142, loss = 1.07077530\n",
      "Iteration 143, loss = 1.07093709\n",
      "Iteration 144, loss = 1.07001233\n",
      "Iteration 145, loss = 1.07017954\n",
      "Iteration 146, loss = 1.06967954\n",
      "Iteration 147, loss = 1.06931810\n",
      "Iteration 148, loss = 1.06874025\n",
      "Iteration 149, loss = 1.06782593\n",
      "Iteration 150, loss = 1.06881757\n",
      "Iteration 151, loss = 1.06893970\n",
      "Iteration 152, loss = 1.06760839\n",
      "Iteration 153, loss = 1.06750712\n",
      "Iteration 154, loss = 1.06682860\n",
      "Iteration 155, loss = 1.06642811\n",
      "Iteration 156, loss = 1.06692038\n",
      "Iteration 157, loss = 1.06693117\n",
      "Iteration 158, loss = 1.06570878\n",
      "Iteration 159, loss = 1.06583977\n",
      "Iteration 160, loss = 1.06573034\n",
      "Iteration 161, loss = 1.06509127\n",
      "Iteration 162, loss = 1.06515269\n",
      "Iteration 163, loss = 1.06536888\n",
      "Iteration 164, loss = 1.06519843\n",
      "Iteration 165, loss = 1.06501285\n",
      "Iteration 166, loss = 1.06473589\n",
      "Iteration 167, loss = 1.06452725\n",
      "Iteration 168, loss = 1.06298882\n",
      "Iteration 169, loss = 1.06381648\n",
      "Iteration 170, loss = 1.06297514\n",
      "Iteration 171, loss = 1.06358246\n",
      "Iteration 172, loss = 1.06285428\n",
      "Iteration 173, loss = 1.06220135\n",
      "Iteration 174, loss = 1.06193610\n",
      "Iteration 175, loss = 1.06216116\n",
      "Iteration 176, loss = 1.06260037\n",
      "Iteration 177, loss = 1.06134627\n",
      "Iteration 178, loss = 1.06139296\n",
      "Iteration 179, loss = 1.06063045\n",
      "Iteration 180, loss = 1.06076062\n",
      "Iteration 181, loss = 1.06050672\n",
      "Iteration 182, loss = 1.06074688\n",
      "Iteration 183, loss = 1.06057031\n",
      "Iteration 184, loss = 1.06071272\n",
      "Iteration 185, loss = 1.05925894\n",
      "Iteration 186, loss = 1.05938259\n",
      "Iteration 187, loss = 1.05886695\n",
      "Iteration 188, loss = 1.05824534\n",
      "Iteration 189, loss = 1.05830640\n",
      "Iteration 190, loss = 1.05837865\n",
      "Iteration 191, loss = 1.05739751\n",
      "Iteration 192, loss = 1.05764525\n",
      "Iteration 193, loss = 1.05630469\n",
      "Iteration 194, loss = 1.05741661\n",
      "Iteration 195, loss = 1.05626255\n",
      "Iteration 196, loss = 1.05682419\n",
      "Iteration 197, loss = 1.05698690\n",
      "Iteration 198, loss = 1.05584330\n",
      "Iteration 199, loss = 1.05650699\n",
      "Iteration 200, loss = 1.05464234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vision\\.conda\\envs\\Tensor\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(20, 50),\n",
       "              learning_rate_init=0.01, solver='sgd', verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "treemodel.score(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentenc,listofmodel):\n",
    "    word=sentenc\n",
    "    sentenc=proccessReview(sentenc)\n",
    "    Arraysentence=[sentenc]\n",
    "    \n",
    "    sentenc=toknizer.texts_to_sequences(Arraysentence)\n",
    "    \n",
    "    \n",
    "    sentenc=pad_sequences(sentenc,padding='post',maxlen=50)\n",
    "\n",
    "    for modell in listofmodel:\n",
    "        \n",
    "        if(modell=='Tensorflow'):\n",
    "            print('TensorFlow:',word,model.predict(sentenc))\n",
    "        elif (modell=='sklearn'):\n",
    "            print('sklearn:',word,mlp.predict(sentenc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: ممتاز النظافه والطاقم متعاون  [1]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
